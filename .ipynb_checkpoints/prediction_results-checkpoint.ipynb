{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000000)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = sorted([i for i in os.listdir('data/') if i.startswith('results_df')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the csvs that have written out from the previous process\n",
    "csvs = sorted([i for i in os.listdir('data') if i.startswith('results_df')])\n",
    "results_df = pd.DataFrame()\n",
    "for csv in csvs:\n",
    "    t = pd.read_csv('data/' + csv)\n",
    "    results_df = pd.concat([results_df, t], axis=0)\n",
    "\n",
    "results_df = results_df.drop(columns='Unnamed: 0')\n",
    "clean_df = pd.read_csv('data/play_by_play_2016.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['Fielders Choice', 'Sacrifice Fly', 'Fielder\\'s Choice-Adv-2nd', \n",
    "               'Sacrifice Bunt', 'Reached on error-Adv-3rd', 'Reached on error-Adv-2nd', \n",
    "               'Catcher Interference', 'Sacrifice Bunt-Adv-2nd', 'Sacrifice Bunt', \n",
    "               'Dirt Ball', 'Sacrifice Fly-Adv-2nd', 'Fielders Choice - Out at 2nd', \n",
    "               'Sacrifice Fly-Adv-1st', 'Sacrifice Bunt-Adv-1st', 'Reached On Error - Out at 2nd', \n",
    "               'Balk', 'Reached on error', 'Hit by pitch']\n",
    "\n",
    "high_level_groupings = {\n",
    "    'ball' : ['Ball', 'Intentional Ball', 'Pitch Out'], \n",
    "    \n",
    "    'strike' : \n",
    "        ['Strike Looking', 'Strike Swinging', ' Strike Swinging - Out at Home', \n",
    "         'Strike-swinging-Adv-1st', 'Strike-looking-Adv-1st', 'Single - Out at 3rd', \n",
    "         'Strike Looking - Out at 1st'], \n",
    "    \n",
    "    'contact_in_play_out' : \n",
    "        ['Pop Out', 'Ground Out', 'Fly Out', 'Line Out'], \n",
    "    \n",
    "    'contact_in_on_base' : \n",
    "        ['Homerun', 'Single', 'Double', 'Single - Out at 2nd', 'Triple', 'Single-Adv-2nd', \n",
    "         'Double-Adv-3rd', 'Double Out at 3rd', 'Single-Adv-Home', 'Single-Adv-3rd', 'Double-Adv-Home', \n",
    "         'Triple-Adv-Home', 'Triple - Out at Home', 'Double-Adv-Home'], \n",
    "    \n",
    "    'contact_foul' : ['Foul Ball', 'Foul Tip', ]\n",
    "}\n",
    "\n",
    "# remove any bat_id with 'rare' events (~10% of at-bats)\n",
    "remove_ids = clean_df.loc[clean_df['outcomeDescription'].isin(remove_cols)]['bat_id'].unique()\n",
    "clean_df = clean_df.loc[~clean_df['bat_id'].isin(remove_ids)]\n",
    "\n",
    "# theres currently no assignment for a walk; create new column for outcome called walk\n",
    "clean_df['walk_flag'] = np.where(\n",
    "    ((clean_df['startingBalls'] == 3) & \n",
    "     (clean_df['outcomeDescription'].isin(high_level_groupings['ball']))), 1, 0\n",
    ")\n",
    "\n",
    "# do the same for strikes\n",
    "clean_df['strikeout_flag'] = np.where(\n",
    "    ((clean_df['startingStrikes'] == 2) & \n",
    "    (clean_df['outcomeDescription'].isin(high_level_groupings['strike']))), 1, 0\n",
    ")\n",
    "\n",
    "# put the previous ids in the data\n",
    "clean_df['prev_state_id'] = (\n",
    "    clean_df.sort_values(by=['bat_id', 'event_num'], ascending=True)\n",
    "      .groupby('bat_id')['outcomeId']\n",
    "      .shift(1)\n",
    "      .fillna('bFP')\n",
    ")\n",
    "\n",
    "clean_df['prev_state_desc'] = (\n",
    "    clean_df.sort_values(by=['bat_id', 'event_num'], ascending=True)\n",
    "      .groupby('bat_id')['outcomeDescription']\n",
    "      .shift(1)\n",
    "      .fillna('First Pitch')\n",
    ")\n",
    "\n",
    "# assign based on the dictonary above\n",
    "clean_df['assigned_outcome'] = ''\n",
    "clean_df['prev_assigned_outcome'] = ''\n",
    "for outcome, grouping in high_level_groupings.items(): \n",
    "    clean_df['assigned_outcome'] = np.where(\n",
    "        clean_df['walk_flag'] == 1, 'walk', \n",
    "            np.where(clean_df['strikeout_flag'] == 1, 'strikeout',\n",
    "                np.where(\n",
    "                    clean_df['outcomeDescription'].isin(grouping), outcome, clean_df['assigned_outcome']\n",
    "                )\n",
    "            )          \n",
    "        )\n",
    "    \n",
    "    # has the previous outcomes as the same grouping (except itis imporssible to get a walk here)\n",
    "    clean_df['prev_assigned_outcome'] = np.where(\n",
    "            clean_df['prev_state_desc'] == 'First Pitch', 'first_pitch',\n",
    "            np.where(\n",
    "                clean_df['prev_state_desc'].isin(grouping), outcome, clean_df['prev_assigned_outcome']\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see how many I got 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for predicted outcome\n",
    "prob_cols = [\n",
    "    'ball', 'contact_foul', 'contact_in_on_base', \n",
    "    'contact_in_play_out', 'strike', 'strikeout', 'walk'\n",
    "]\n",
    "\n",
    "results_df['max_prob'] = results_df[prob_cols].max(axis=1)\n",
    "results_df['predicted_result'] = ''\n",
    "\n",
    "for prob_col in prob_cols: \n",
    "    results_df['predicted_result'] = np.where(\n",
    "        results_df[prob_col] ==  results_df['max_prob'], \n",
    "        prob_col, results_df['predicted_result'] \n",
    "        \n",
    "    )\n",
    "    \n",
    "# create a marker when I got the 'right' outcome\n",
    "results_df['correct_flag'] = np.where(\n",
    "        results_df['predicted_result'] ==  results_df['actual_outcome'], 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at accuracy \n",
    "results_df['correct_flag'].sum() / results_df['correct_flag'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I randomly assign based on percentiles from real data \n",
    "# how well do I do \n",
    "# not the greatest way - because a 'good' model should almost never predict basehits\n",
    "pct_df = clean_df.groupby('assigned_outcome').agg({'pitch_id' : 'count'}).reset_index()\n",
    "pct_df['pct'] = pct_df['pitch_id'] / pct_df['pitch_id'].sum()\n",
    "pct_df = pct_df[['assigned_outcome', 'pct']]\n",
    "outcomes, chance = pct_df['assigned_outcome'].tolist(), pct_df['pct'].tolist()\n",
    "\n",
    "chance_df = results_df\n",
    "chance_df['random_outcome'] = np.random.choice(a=outcomes, p=chance, size=len(results_df))\n",
    "\n",
    "chance_df['random_correct_flag'] = np.where(\n",
    "    results_df['predicted_result'] ==  results_df['random_outcome'], 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_df['random_correct_flag'].sum() / chance_df['random_outcome'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distrubution for all of the columns that you kept\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for index, col in enumerate(prob_cols, start=1): \n",
    "    plt.subplot(3, 3, index)\n",
    "    sns.histplot(results_df[col]).set(title=f'Histogram for {col.title()} Predictions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at these distrubutions by the current count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = clean_df[['pitch_id', 'startingBalls', 'startingStrikes']]\n",
    "# now look at the various histograms by the count of the play\n",
    "ball_stike_df = results_df.merge(right=count_df, on=['pitch_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create total columns for balls and strikes\n",
    "ball_stike_df['total_ball_pct'] = np.where(\n",
    "    ball_stike_df['walk'].isnull(), ball_stike_df['ball'], ball_stike_df['walk']\n",
    ")\n",
    "\n",
    "ball_stike_df['total_strike_pct'] = np.where(\n",
    "    ball_stike_df['strikeout'].isnull(), ball_stike_df['strike'], ball_stike_df['strikeout']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_dists(event_type): \n",
    "    bs_combos = [(0, 0), (1, 0), (2, 0), (3,0), (1, 1), (2, 1), (3,1), (3, 2), (1, 2), (2, 2)]\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for index, bs_combo in enumerate(bs_combos, start=1): \n",
    "        ball_stike_df_current = ball_stike_df.loc[\n",
    "            ((ball_stike_df['startingBalls'] == bs_combo[0]) & \n",
    "             (ball_stike_df['startingStrikes'] == bs_combo[1]))\n",
    "        ]\n",
    "\n",
    "        plt.subplot(4, 3, index)\n",
    "\n",
    "        sns.histplot(ball_stike_df_current[event_type], kde=True)\\\n",
    "           .set(title=f'Histogram for {col.title()} Predictions')\n",
    "\n",
    "        plt.xlim(0, 1)\n",
    "        plt.xticks(np.arange(0, 1, .1))\n",
    "        plt.title(f'Histogram for {bs_combo}')\n",
    "        \n",
    "    plt.suptitle(f'{event_type} by Pitch Count', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show(); \n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "event_types = ['total_ball_pct', 'total_strike_pct', 'contact_foul', 'contact_in_on_base']\n",
    "for event_type in event_types:\n",
    "    compute_count_dists(event_type=event_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the accuacy for each moment (if I give a 30% chance of it happening - it should happen ~30% of the time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin each forcast into .02 buckets for evaluation\n",
    "bins = np.arange(0, 1, .0025)\n",
    "binned_df = results_df\n",
    "prob_cols = prob_cols + ['max_prob']\n",
    "\n",
    "for c in prob_cols: \n",
    "    # create a placeholder columns\n",
    "    binned_df[f'{c}_bin'] = None\n",
    "    for i in range(len(bins)-1): \n",
    "        binned_df[f'{c}_bin'] = np.where(\n",
    "            binned_df[c].between(bins[i], bins[i+1]), bins[i], binned_df[f'{c}_bin']\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(outcome): \n",
    "    outcome_df = binned_df.loc[binned_df['predicted_result'] == outcome]\n",
    "    accuracy_df = (\n",
    "        outcome_df.groupby(f'{outcome}_bin').agg(\n",
    "            total_predicted=('correct_flag', 'sum'),\n",
    "            total_occured=('correct_flag', 'count') \n",
    "    )).reset_index()\n",
    "    \n",
    "    accuracy_df['pct'] = accuracy_df['total_predicted'] / accuracy_df['total_occured']\n",
    "    \n",
    "    # take only the top 99 percent \n",
    "    \n",
    "    x_vals, y_vals = accuracy_df['pct'].to_numpy(), accuracy_df[f'{outcome}_bin'].to_numpy()\n",
    "    \n",
    "    # fit a polynomial to the values\n",
    "    _x_vals = np.linspace(x_vals[0], x_vals[-1], 500)\n",
    "    coef = np.polyfit(x_vals, y_vals, 3)\n",
    "    poly = np.poly1d(coef)\n",
    "    _y_vals = poly(_x_vals)\n",
    "    \n",
    "    plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    # plot the scatter points\n",
    "    plt.scatter(x=x_vals, y=y_vals)\n",
    "    \n",
    "    # plot a perfect fit\n",
    "    plt.axline((0, 0), slope=1, color='black', linestyle='--', transform=plt.gca().transAxes, label='Perfect Prediction Line')\n",
    "    \n",
    "    # plot the polynomial fit\n",
    "    plt.plot(_x_vals, _y_vals, linestyle=':',label='Polynomal Fit', color='blue')\n",
    "    \n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xticks(np.arange(0, 1, .1))\n",
    "    plt.yticks(np.arange(0, 1, .1))\n",
    "    plt.ylabel('Predicted Probibility of Event Happening', fontsize=14)\n",
    "    plt.xlabel('Percentage time Event Happening', fontsize=14)\n",
    "    plt.title(f'Calibration Plot for {outcome.title()}', fontsize=16)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    return accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outcomes = ['ball', 'strike', 'contact_foul', 'contact_in_on_base', 'contact_in_play_out']\n",
    "for outcome in outcomes: \n",
    "    plot_accuracy(outcome=outcome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
